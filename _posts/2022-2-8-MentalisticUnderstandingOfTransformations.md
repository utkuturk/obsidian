---
layout: post
author: Utku Turk
title: Mentalistic Understanding of Transformations
---

# Mentalistic Understanding of Transformations

[[Classnotes MOC]]|[[Psycholing Classnotes]]|[[Learning Wh-Gaps, Utku Turk]]

**Date**:: 2022-02-08

**Class**:: Psycholinguistics II

**Tags**:: #umd #classnotes  #umd/psylx

âˆ«Miller62: Transformational Cube.

_What are the mentalistic claims about transformations?_

Let's start with effects at verb position. English fronts wh-words. How is the wh-word is linked to the verb?

- gap-based approach
	- The verb object relation is always there. Sometimes, it is not overtly there and the relation is not there as well. You may have then additional link between the gap and the wh-word.
	- Double structure encoding.
- direct association
	- it is linked to the verb as it would be linked-directly if it were an object. 
	- Single structure encoding.

What if we try to test steps of derivations? But it is difficult to directly use grammatical rules. 

### Basic Parsing Systems
$\cdot$ represents when the rule formation 

Bottom up = Det N $\cdot$ 

Left corner = Det $\cdot$ N

Top down = $\cdot$ Det N

Arnold read some books

<u>Bottom up</u>
after reading this NP(Arnold) V(read), nothing to do

NP(Arnold) V(read) Det(some), still nothing.

NP(Arnold) V(read) Det(some) N(Books),
	- Now we form NP(Det N) > VP(V NP) > S(NP VP)


Strict bottom up parsing does not explain incrementality

<u>Left Corner</u>

NP(Arnold) > we go up See S, and form S(NP $\_$)

Then we see read we can form S(NP VP(V $\_$))

Then we see some, we can form S(NP VP(V NP(Det $\_$)))

Finally we see books, now we do have the full thing. S(NP VP(V NP(Det N)))

Left corner parser allows us to hypothesize orphan structures, it also allow us to entertain multiple structures. Bottom up parsing by definition do not do this.

<u>Top down</u>

...

If we take transformations literally, it is going to be really hard to use it as a identification device. 

a = X$_1$ wh-NP X$_2$

b = wh-NP X$_1$ 0 X$_2$

it is easy to derive b from a, but really hard to derive a from b.


_Surface Structures_
- Garrett, Bever, Fodor 1969
- as a direct result of their new invention's influence the **com**pany was given an award.
- the retiring chairman whose methods still greatly influence the **com**pany was given an award.

People heard these sentences, and a click with **com**. People misreport when they heard the click. In the first sentence, click moves back to the sentence boundary. In the second one, it moves forward, at the end of word company.

People were illusioning where they hear the click, and these would align with hiden structures.

_Deep Structures_

Cued recall (Wanner, 1968)
- The governor asked the detective to prevent drinking
	- the detective is argument of ask, prevent, but not drink
- The governor asked the detective to cease drinking
	- the detective is argument of ask, prevent, and **drink**

Cue: detective. More effective for cease than for prevent. 

Sachs (1967, 1974): memory for content, not structure. Structures persist, as well as meaning, but they are independent of each other

Bransford & Franks (1971)

	Highest recognition confidence intervals for full sentence never seen before!

Bransford, Barclay, Franks 1972
- Three turtles rested on a floating log and a fish swam beneath it.
- Three turtles rested on a floating log and a fish swam beneath them.
- They argued that, what persisted was not memory, or ling structure, but it was the representation

<u>Takeaway</u>

Surface structure yep

deep? maybe...

transformations??? NOPE!

the idea that "Backward" building (from b to a) is not very logical was more logical.

_Cross modal priming_

could you see evidence this mediated encoding, that is transformations?

- which boy did the old man from Osaka meet at the station

they decide on "boy" faster in positions after from or meet than they decide for "girl"

- you hear the sentence, and you see some words, and when you see the words in certain positions you decide on whether you saw that word.
- why dont we look at other positions? 

_Pickering & Barry 1991_

- to which child did the teacher give **a long speech about the importance of honesty** $\_\_\_$?
- they saw that people formed relation with the verb.
- but these are ditransitive, with which people can form give $\_\_$ a long speech ...
- Or, we can say that we already know what $give$ does, and $give$'s arguments. So we can form heuristic arguments when we see the verb. 

Timing evidence as theoretical arbitration works when theories make timing predictions. 

Relation structures and time in linguistics and psycholinguistics, Phillips & Wagers 2007

### not so obvious variation
- example 1 pronoun interpretation

While John was reading the book, he ate an apple

while he was reading the book, John ate an apple. russian not ok, english ok

John ate an apple while he was reading the book.

He ate an apple while John was reading the book. impossible in all languages


example 2 constratin onquestions

what do you think sally ate?

what do you think that sally ate?

who do you think ate the donut?

who do you think that ate the donut? not ok in English, ok in Italian
- do we learn this?
- maybe it is in genome? maybe something related to this is in genome

variation might be linked to the possibility of post-verbal subjects.

it is not about the corpus, because the second question is also less heard.

Languages that allow post-verbal subjects also allow the red example

Post-verbal subjects are easy for learners to observe.